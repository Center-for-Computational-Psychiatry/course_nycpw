{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdqMQVxqCNvr"
      },
      "source": [
        "# Introduction to Reinforcement Learning (RL)\n",
        "\n",
        "**Angela Radulescu**\n",
        "\n",
        "New York Computational Psychiatry Workshop\n",
        "\n",
        "Nov. 10th, 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WcPGvpJeXl0"
      },
      "source": [
        "\n",
        "Please start by making your own copy of this Google Colab notebook (you will need a Google account).\n",
        "\n",
        "Today, we will learn how to use reinforcement learning (RL) to simulate behavior in different environments (tasks). This tutorial is intended to get you spinning up your own RL algorithms for a task of your choice. As we go along, we will go over both formal definitions and code.\n",
        "\n",
        "Let us dive in! Go ahead and run the cell below to import some necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "vT1TdpIdaJbP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etdw0v5vGPIi"
      },
      "source": [
        "## What is reinforcement learning?\n",
        "\n",
        "**Reinforcement learning (RL)** refers to a set of learning processes that allow agents to make adaptive decisions over time in order to achieve a **goal**. What makes RL different from other types of learning (e.g. supervised learning) is that the feedback used to change behavior (i.e., the **reinforcement**) can be:\n",
        "\n",
        "1. **Sparse** -- reinforcement doesn't have to occur often\n",
        "2. **Delayed** -- reinforcement can occur after many actions are taken\n",
        "3. **Uncertain** -- an action may not always result in reinforcement\n",
        "\n",
        "*Discussion question*: what are examples of RL that you have encountered in your work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrFPCV1hGgCd"
      },
      "source": [
        "## Foundations\n",
        "\n",
        "RL starts from the concept of an **agent** that is acting in an **environment**.\n",
        "\n",
        "You can think of RL as a sort of \"physics of behavior.\" It is a set of mathematical formulas that describe how intelligent agents interact with the *external* world. And how that interaction changes their *internal* world (e.g, desires, cognition, beliefs). \n",
        "\n",
        "At any given **timepoint** $t$, the agent can be in one of many **states** $s_t \\in S$ of the environment, and decide to take one of many **actions** $a_t \\in A$. Taking a particular action might switch the agent from $s_t$ to a new state $s_{t+1}$. Once an action is taken, the environment also responds with a reward $r_{t}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvZFhw2wTQ21"
      },
      "source": [
        "![mdp.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNBzaihUQfZ"
      },
      "source": [
        "*Discussion question*: how would you define the states and actions of a decision-making scenario that you have encountered in your work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIJw2nri1frb"
      },
      "source": [
        "### Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x2ic0TNTNkJ"
      },
      "source": [
        "How the environment reacts to the agent's actions is defined by a **model**, which the agent may or may not know. The model has two main components: the transition function $T$ and the reward function $R$.\n",
        "\n",
        "Let’s say when we are in state $s$, we decide to take action $a$ to arrive in the next state $s’$ and obtain reward $r$. We refer to this as a **transition** step, represented by a tuple $(s, a, s’, r)$. You can think of this tuple as a unit of experience that the agent gets to learn from.\n",
        "\n",
        "The (repeated) tuples the agent will experience depend on how $T$ and $R$ are defined.\n",
        "\n",
        "The transition function $T$ defines the probability of transitioning from state $s$ to state $s'$ after taking action $a$ while obtaining reward $r$ (here $\\mathbb{P}$ stands for ``probability\").\n",
        "\n",
        "$$\n",
        "P(s',r | s,a) = \\mathbb{P}[S_{t+1} = s', R_{t} = r | S_t = s, A_t = a]\n",
        "$$\n",
        "\n",
        "The reward function $R$ predicts the next reward triggered by one action:\n",
        "\n",
        "$$\n",
        "R(s,a) = \\mathbb{E}[R_{t+1} | S_t = s, A_t = a] = \\sum\\limits_{r \\in R}r\\sum\\limits_{s' \\in S}P(s',r|s,a)\n",
        "$$\n",
        "\n",
        "*Example*: let's unpack this some more using a simple \"Corridor\" environment depicted below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TxlRWgui7y-"
      },
      "source": [
        "![corridor_env.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu954t_sjpvr"
      },
      "source": [
        "The \"Corridor\" environment has the following properties:\n",
        "\n",
        "The state space consists of 3 states. The agent starts in State $1$ (Start), and can reach one of two **terminal** states, State $0$ (Hole) and State $2$ (Goal). When the agent reaches a terminal state, the **episode** (defined as a sequence of experience tuples) ends.\n",
        "\n",
        "$$\n",
        "s \\in S = \\{0, 1, 2\\}\n",
        "$$\n",
        "\n",
        "The action space consists of two actions available to the agent: Action $0$ (Left) and Action $1$ (Right).\n",
        "\n",
        "$$\n",
        "a \\in A = \\{0, 1\\}\n",
        "$$\n",
        "\n",
        "The \"Corridor\" has a **deterministic** transition function: a *Left* action always moves the agent to the left, and a *Right* action always moves the agent to the right.\n",
        "\n",
        "The \"Corridor\" reward function gives a +1 when the agent moves into State $2$ (*Goal*) and 0 otherwise.\n",
        "\n",
        "A convenient way to represent the model of the \"Corridor\" environment is in table form:\n",
        "\n",
        "| State  | Action  | Next state  | Transition probability  | Reward  |\n",
        "|-----------|-----------|-----------|-----------|-----------|\n",
        "| 0 (Hole) | 0 (Left) | 0 (Hole) | 1  | 0 |\n",
        "| 0 (Hole) | 1 (Right) | 0 (Hole) | 1  | 0 |\n",
        "| 1 (Start) | 0 (Left) | 0 (Hole) | 1  | 0 |\n",
        "| 1 (Start) | 1 (Right) | 0 (Goal) | 1  | +1 |\n",
        "| 2 (Goal) | 0 (Left) | 2 (Goal) | 1  | 0 |\n",
        "| 2 (Goal) | 1 (Right) | 2 (Goal) | 1  | 0 |\n",
        "\n",
        "*Exercise*: Using the formula for the reward function above, compute the reward the agent would expect to get if it starts in the Start state and moves Right.\n",
        "\n",
        "Let us now code up this environment. To define different components of our simulation, we will make use of [object oriented programming (OOP)](https://realpython.com/python3-object-oriented-programming/). OOP is helpful because it lets us define general classes we can reuse across different simulations to create new instances of each component (e.g. different instances of an agent, environment, etc).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "XIg-aB8Hd0Ak"
      },
      "outputs": [],
      "source": [
        "class Corridor(object):\n",
        "\n",
        "  \"\"\"Class for the corridor environment.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    self.n_states = 3\n",
        "    self.n_actions = 2\n",
        "    self.states = np.arange(0, self.n_states)\n",
        "    self.actions = np.arange(0, self.n_actions)\n",
        "    self.reward_location = self.n_states\n",
        "\n",
        "    self.state = 1 # begin in Start state\n",
        "    self.t = 0     # reset timstep\n",
        "    self.terminate = False\n",
        "\n",
        "  def visualize(self):\n",
        "\n",
        "    print(\"Green is the Goal state\")\n",
        "\n",
        "    xs = np.arange(0, self.n_states+1, 1)\n",
        "    ys = np.arange(0, 2)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(self.n_states,1))\n",
        "    # grid \"shades\" (boxes)\n",
        "    w, h = xs[1] - xs[0], ys[1] - ys[0]\n",
        "    for i, x in enumerate(xs[:-1]):\n",
        "        for j, y in enumerate(ys[:-1]):\n",
        "            if (i == self.reward_location - 1):\n",
        "                ax.add_patch(Rectangle((x, y), w, h, fill=True, color='#008610', alpha=.1))\n",
        "    # grid lines\n",
        "    for x in xs:\n",
        "        plt.plot([x, x], [ys[0], ys[-1]], color='black', alpha=.33, linestyle=':')\n",
        "    for y in ys:\n",
        "        plt.plot([xs[0], xs[-1]], [y, y], color='black', alpha=.33, linestyle=':')\n",
        "\n",
        "    ax.set_xticks(xs[:-1]+0.5)\n",
        "    ax.set_xticklabels(xs[:-1]+1)\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xlabel('State', fontsize=15)\n",
        "\n",
        "    plt.tick_params(left = False)\n",
        "    plt.show()\n",
        "\n",
        "  def step(self, action):\n",
        "\n",
        "    # the step method takes as input a state and action and changes the environment\n",
        "    # this is where we encode the environment's true model (T and R)\n",
        "\n",
        "    assert self.state in self.states, \"Invalid state\"\n",
        "    assert action in self.actions, \"Invalid action\"\n",
        "\n",
        "    if self.state == 1:\n",
        "      print('New episode')\n",
        "\n",
        "    print('Current state: ' + str(self.state))\n",
        "\n",
        "    if action == 0:\n",
        "      print('Action: left')\n",
        "    else:\n",
        "      print('Action: right')\n",
        "\n",
        "    if self.state == 1:\n",
        "\n",
        "        if action == 0:    # agent picks left\n",
        "            self.state = 0\n",
        "            reward = 0\n",
        "        else:              # agent picks right\n",
        "            self.state = 2\n",
        "            reward = 1\n",
        "        self.terminate = 1\n",
        "        print('+ ' + str(reward) + ' reward')\n",
        "\n",
        "    elif self.state == 0:\n",
        "        self.state = 0\n",
        "        reward = 0\n",
        "        self.terminate = True\n",
        "        print('+ ' + str(reward) + ' reward')\n",
        "\n",
        "    elif self.state == 2:\n",
        "        self.state = 2\n",
        "        reward = 0\n",
        "        self.terminate = True\n",
        "        print('+ ' + str(reward) + ' reward')\n",
        "\n",
        "    print('New state: ' + str(self.state))\n",
        "\n",
        "    # increment timestep\n",
        "    self.t = self.t + 1\n",
        "    if self.terminate == True:\n",
        "      self.reset()\n",
        "      print('End of episode')\n",
        "\n",
        "    return self.state, reward\n",
        "\n",
        "  def reset(self):\n",
        "\n",
        "    # the reset method resets the environment to its start state\n",
        "    self.state = 1\n",
        "    self.terminate == False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "hvTXpNkWdUSr",
        "outputId": "7a765558-9d62-4f70-a7fd-a966d11b4c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Green is the Goal state\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# This line creates an instance of the Corridor class\n",
        "env = Corridor()\n",
        "\n",
        "env.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntsPeosykV_M",
        "outputId": "82b9d60f-e892-42e5-e4f0-a799de4eaa12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New episode\n",
            "Current state: 1\n",
            "Action: right\n",
            "+ 1 reward\n",
            "New state: 2\n",
            "End of episode\n"
          ]
        }
      ],
      "source": [
        "# This line takes an action and steps through the environment\n",
        "new_state, reward = env.step(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoFfvrdOoyG5"
      },
      "source": [
        "Some transition functions are **probabilistic**, meaning that the same action can lead to different states with different probabilities.\n",
        "\n",
        "*Exercise*: How would you modify the Corridor environment's step function to encode a transition function in which an action works as intended 80% of the time, but 20% of the time the agent \"slips\" and an action takes the agent to the opposite state?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h37pAeuNaDyW"
      },
      "source": [
        "We may or may not know how the model works and this differentiates two types of RL:\n",
        "\n",
        "1.   **Model-based RL** - rely on the model of the environment to decide how to act; know the model in advance, or learn it from experience  \n",
        "2.   **Model-free RL** - no dependency on the model during learning and action selection\n",
        "\n",
        "Together, these elements (state space $S$, action space $A$, transition function $T$ and reward function $R$) define a **Markov Decision Process (MDP)**. You can think of the MDP as an abstract definition of a particular **task** an agent has to solve.\n",
        "\n",
        "*Discussion question*: what are some examples of tasks that come to mind which can be thought of in this way?\n",
        "\n",
        "All states in an MDP have the “Markov” property, referring to the fact that the future only depends on the current state, not the history. Or, in other words, the future and the past are conditionally independent given the present, as the current state encapsulates all the statistics we need to decide the future. This is one of the main **assumptions** of RL (assumption = what we take to be true from the start).   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfdSbdhZ1nDR"
      },
      "source": [
        "### Agent\n",
        "\n",
        "Another key assumption of RL is that an agent's objective is to maximize long term future reward. This future reward is known as **return**, and it is defined as the total sum of discounted rewards going forward:\n",
        "\n",
        "$$\n",
        "G_t = R_{t+1} + \\gamma R_{t+2} + ...  = \\sum\\limits_{k = 0}^{\\infty} \\gamma^k R_{t+k+1}\n",
        "$$\n",
        "\n",
        "The discount factor $\\gamma \\in [0, 1]$ downweights rewards in the future. It is there for mathematical convenience (we don't need to track future steps forever to compute a return), but also has an interesting psychological interpretation -- we know humans tend to discount benefits that are not immediate.\n",
        "\n",
        "The agent's **behavior** is represented by a **policy** $\\pi$ which encodes what action to take in each state $s$. You can think of this as a function that maps between states and action. This mapping can be either deterministic (always take the same action in a state) or stochastic (take different actions with different probabilities):\n",
        "\n",
        "$$\n",
        "\\text{Deterministic}: \\pi(s) = a\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Stochastic}: \\mathbb{P}_\\pi[A = a|S = s]\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b91sK52eyeeY"
      },
      "source": [
        "### Value\n",
        "\n",
        "Most RL algorithms in the literature rely on the concept of **value**. Value measures the general \"goodness\" of a **state** or **state-action** pair: how good is it to be in a state, or how good is it to be in a state and do an action? You can think of these two types of value as mapping onto Pavlovian and instrumental control. From this perspective, Pavlovian learning refers to learning reward predictions; instrumental learning refers to learning what to do, given reward predictions.   \n",
        "\n",
        "The state-value of a state $s$ is the expected return if we are in this state at time $t$, $S_t = s$:\n",
        "\n",
        "$$\n",
        "V_{\\pi}(s) =  \\mathbb{E}_\\pi[G_t | S_t = s]\n",
        "$$\n",
        "\n",
        "Similarly, we define the action-value (\"Q-value\") of a state-action pair as:\n",
        "\n",
        "$$\n",
        "Q_{\\pi}(s,a) =  \\mathbb{E}_\\pi[G_t | S_t = s, A_t = a]\n",
        "$$\n",
        "\n",
        "By definition, the optimal value function produces the maximum return:\n",
        "\n",
        "$$\n",
        "V_*(s) = \\max\\limits_{\\pi}V_{\\pi}(s)\n",
        "$$\n",
        "\n",
        "$$\n",
        "Q_*(s, a) = \\max\\limits_{\\pi}Q_{\\pi}(s, a)\n",
        "$$\n",
        "\n",
        "And the optimal policy achieves the optimal value functions:\n",
        "\n",
        "$$\n",
        "\\pi_* = \\underset{\\pi}{\\mathrm{argmax}} \\ V_\\pi(s)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\pi_* = \\underset{\\pi}{\\mathrm{argmax}} \\ Q_\\pi(s,a)\n",
        "$$\n",
        "\n",
        "Most RL algorithms you will encounter in the computational psychiatry literature assume reward maximization defined as above, and aim to have the agent (e.g. human participants, rodents, monkeys) learn the optimal value function and/or the optimal policy. While this discussion is beyond the scope of our tutorial, the limits of this assumption is a matter of active debate in cognitive science ([Juechems & Summerfield](https://arxiv.org/pdf/2407.10583)) and AI ([Silver et al.](https://www.sciencedirect.com/science/article/pii/S0004370221000862), [Abel et al.](https://rlj.cs.umass.edu/2024/papers/RLJ_RLC_2024_89.pdf)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlP4TEpV70iM"
      },
      "source": [
        "### Bellman equations\n",
        "\n",
        "The **Bellman equations** are a set of recursive update equations that, given complete information of the environment, can be used to directly compute value functions.  These equations decompose the value function into the immediate reward plus the discounted future values.\n",
        "\n",
        "#### Expectation equations\n",
        "\n",
        "$$\n",
        "V_\\pi(s) = \\sum\\limits_{a \\in A} \\pi(a | s) (R(s,a) + \\gamma  \\sum\\limits_{s' \\in S}P_{s,s'}^aV_\\pi(s'))\n",
        "$$\n",
        "\n",
        "Unpacking the terms:\n",
        "* $V_\\pi(s)$ = the value of state $s$ when following policy $\\pi$\n",
        "* $\\pi(a|s)$ = the probability of choosing action $a$ in state $s$\n",
        "* $R(s,a)$ = the immediate reward obtained after taking action $a$ in state $s$\n",
        "* $\\gamma$ = discount factor\n",
        "* $P_{s,s'}^a$ = probability of ending up in $s'$ after taking action $a$ in *s*\n",
        "* $V_\\pi(s')$ = the value of state $s'$ when following policy $\\pi$\n",
        "\n",
        "*Discussion question*: does this logic make intuitive sense? Why or why not?\n",
        "\n",
        "We can write the same kind of relationship for the **state-action value**:\n",
        "\n",
        "$$\n",
        "Q_\\pi(s,a) = R(s,a) + \\gamma   \\sum\\limits_{s' \\in S}P_{s,s'}^a \\sum\\limits_{a' \\in A} \\pi(a',s')Q_\\pi(s',a')\n",
        "$$\n",
        "\n",
        "* $Q_\\pi(s,a)$ = the value of taking action $a$ state $s$ when following policy $\\pi$\n",
        "* $R(s,a)$ = the immediate reward obtained after taking action $a$ in state $s$\n",
        "* $\\gamma$ = discount factor\n",
        "* $P_{s,s'}^a$ = probability of ending up in $s'$ after taking action $a$ in *s*\n",
        "* $\\pi(a|s)$ = the probability of choosing action $a$ in state $s$\n",
        "* $Q_\\pi(s',a')$ = the value of taking action $a'$ state $s'$ when following\n",
        "\n",
        "*Discussion question*: how does this differ from the state value Bellman equation?\n",
        "\n",
        "#### Optimality equations\n",
        "\n",
        "If we are only interested in the **optimal policy**, rather than computing the expectation following any policy, we can modify the expectation equations slightly to compute the maximum returns:\n",
        "\n",
        "$$\n",
        "V_*(s) = \\max\\limits_{a \\in A}(R(s,a) + \\gamma  \\sum\\limits_{s' \\in S}P_{s,s'}^a V_*(s'))\n",
        "$$\n",
        "\n",
        "$$\n",
        "Q_*(s,a) = R(s,a) + \\gamma \\sum\\limits_{s' \\in S} P_{s,s'}^a \\max\\limits_{a' \\in A} Q_*(s',a')\n",
        "$$\n",
        "\n",
        "*Discussion question*: these look very similar to the expectation equations, with a few important differences. What are these differences, and what do they mean for the agent's behavior?\n",
        "\n",
        "#### Dynamic programming\n",
        "\n",
        "In most scenarios, directly applying the Bellman equations to solve MDPs is impractical. Nevertheless, these equations lay the theoretical foundation for many RL algorithms. For small state and actions spaces, we can use **dynamic programming** to solve the equations and determine the optimal policy. This can be useful, for instance in understanding how the value function of an agent might change under different assumptions about the problem.\n",
        "\n",
        "*Discussion question*: why would dynamic programming be impractical for large state and action spaces?\n",
        "\n",
        "*Example paper*: [Zorowitz et al.](https://pubmed.ncbi.nlm.nih.gov/34036174/) used this technique to show how anxious symptomatology can result from relaxing the assumption that the agent makes the return-maximizing choice at each step (as shown in the Bellman optimality equation above)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb_gBaIeSymJ"
      },
      "source": [
        "## Classic RL algorithms\n",
        "\n",
        "We will now discuss two of the most widely used RL algorithms in the literature: **Temporal-Difference Learning** and **Q-Learning**. While remarkably simple, these algorithms have been extensively studied because of the wealth of evidence suggesting that the brain is implementing this form RL (for a detailed discussion, see this review by [Niv](https://www.sciencedirect.com/science/article/pii/S0022249608001181#fig3))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE9EimVQTR4a"
      },
      "source": [
        "### TD-Learning\n",
        "\n",
        "Temporal-Difference Learning is a general purpose algorithm for learning reward predictions which guarantees convergence to the optimal value function in any MDP. It embodies the key intuition of RL, which is using experience to update reward expectations.\n",
        "\n",
        "The update equation for TD-Learning is as follows:\n",
        "\n",
        "$$\n",
        "V(S_{t}) \\leftarrow V(S_t) + \\alpha[R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)]\n",
        "$$\n",
        "\n",
        "Unpacking the terms:\n",
        "* $V(S_t)$ = value of current state\n",
        "* $V(S_{t+1})$ = value of future state\n",
        "* $0 < \\alpha < 1$ = learning rate  \n",
        "* $R_{t+1}$ = immediate reward\n",
        "* $\\gamma$ = discount factor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkLDmvrzzQCg"
      },
      "source": [
        "![track_env.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cXSnk1vzy7R"
      },
      "source": [
        "Let us now implement TD-Learning for a simple environment. Consider a mouse running along a track until it reaches a terminal state where it encounters a piece of cheese. We can abstract this as a \"single track\" in which the agent doesn't take any actions, but simply moves forward on the track."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "NW9m-Mba0Ipt"
      },
      "outputs": [],
      "source": [
        "class SingleTrack(object):\n",
        "\n",
        "  \"\"\"Class for the single track environment.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  n_states : int\n",
        "      Number of states on the track.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_states):\n",
        "\n",
        "    self.n_states = n_states\n",
        "    self.states = np.arange(0, n_states)\n",
        "    self.reward_location = self.n_states\n",
        "\n",
        "    self.state = 1 # begin in Start state\n",
        "    self.t = 0     # reset timstep\n",
        "    self.terminate = False\n",
        "\n",
        "  def visualize(self):\n",
        "\n",
        "    xs = np.arange(0, self.n_states+1, 1)\n",
        "    ys = np.arange(0, 2)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(self.n_states,1))\n",
        "    # grid \"shades\" (boxes)\n",
        "    w, h = xs[1] - xs[0], ys[1] - ys[0]\n",
        "    for i, x in enumerate(xs[:-1]):\n",
        "        for j, y in enumerate(ys[:-1]):\n",
        "            if (i == self.reward_location - 1):\n",
        "                ax.add_patch(Rectangle((x, y), w, h, fill=True, color='#f9b02e', alpha=.8))\n",
        "    # grid lines\n",
        "    for x in xs:\n",
        "        plt.plot([x, x], [ys[0], ys[-1]], color='black', alpha=.33, linestyle=':')\n",
        "    for y in ys:\n",
        "        plt.plot([xs[0], xs[-1]], [y, y], color='black', alpha=.33, linestyle=':')\n",
        "\n",
        "    ax.set_xticks(xs[:-1]+0.5)\n",
        "    ax.set_xticklabels(xs[:-1]+1)\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xlabel('State', fontsize=15)\n",
        "\n",
        "    plt.tick_params(left = False)\n",
        "    plt.show()\n",
        "\n",
        "  def step(self):\n",
        "\n",
        "    print('Current state: ' + str(self.state))\n",
        "    print('Moving right...')\n",
        "    self.state = self.state+1\n",
        "\n",
        "    if (self.state == self.reward_location):\n",
        "        reward = 10;\n",
        "        self.terminate = True\n",
        "    else:\n",
        "        reward = 0;\n",
        "\n",
        "    print('New state: ' + str(self.state))\n",
        "\n",
        "    # increment timestep\n",
        "    self.t = self.t + 1\n",
        "\n",
        "    return self.state, reward\n",
        "\n",
        "  def reset(self):\n",
        "\n",
        "    # the reset method resets the environment to its start state\n",
        "    self.state = 1\n",
        "    self.t = 0     # reset timstep\n",
        "    self.terminate = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "N0UP9TWI0Md0",
        "outputId": "97ab7e1b-0927-42b4-ba65-89e67a82c1e4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "track = SingleTrack(10)\n",
        "track.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF0Qizt-1t8z"
      },
      "source": [
        "Time to code up our first agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "ACm1NcKd1y1P"
      },
      "outputs": [],
      "source": [
        "class TDRL(object):\n",
        "  \"\"\"Class for the TDRL reward prediction algorithm.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  alpha : float, range (0, 1)\n",
        "      Learning rate.\n",
        "\n",
        "  gamma : float, range (0, 1)\n",
        "      Discount factor.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, env, alpha, gamma, v_init = False):\n",
        "\n",
        "    self.a = alpha\n",
        "    self.g = gamma\n",
        "\n",
        "    # initialize values\n",
        "    if v_init: # check if initial values were provided\n",
        "      self.v = np.ones((env.n_states, ))*v_init\n",
        "    else:\n",
        "      self.v = np.zeros((env.n_states, ))\n",
        "\n",
        "    # initialize td-errors\n",
        "    self.d = np.zeros((env.n_states, ))\n",
        "\n",
        "  def update(self, current_state, new_state, reward, verbose=False):\n",
        "\n",
        "    td_error = reward + self.g * self.v[new_state-1] - self.v[current_state-1]\n",
        "\n",
        "    print('delta: ' + str(td_error))\n",
        "\n",
        "    self.d[current_state] = td_error\n",
        "    self.v[current_state-1] = self.v[current_state-1] + self.a * td_error\n",
        "\n",
        "    if verbose == True:\n",
        "      print('delta: ' + str(self.v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1JA0rhM5IuF"
      },
      "source": [
        "It is often convenient to write a simulation function that has the agent and environment interact for a fixed number of trials or episodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "OL0Eu_zq5HIe"
      },
      "outputs": [],
      "source": [
        "def run_simulation(params, n_episodes):\n",
        "\n",
        "  \"\"\"Function for running a simulation of TDRL in the single track environment.\"\"\"\n",
        "\n",
        "  # make environment\n",
        "  env = SingleTrack(params['n_states'])\n",
        "\n",
        "  # initialize agent\n",
        "  agent = TDRL(env, params['alpha'], params['gamma'])\n",
        "\n",
        "  # initialize output containers\n",
        "  V = np.zeros((n_episodes, params['n_states']))\n",
        "  D = np.zeros((n_episodes, params['n_states']))\n",
        "\n",
        "  for e in np.arange(n_episodes):\n",
        "\n",
        "    print(\"Ran the track \" + str(e) + \" times so far\")\n",
        "\n",
        "    for s in np.arange(params['n_states']):\n",
        "\n",
        "      # step through environment\n",
        "      current_state = env.state\n",
        "      _, reward = env.step()\n",
        "      new_state = env.state\n",
        "\n",
        "      # update agent\n",
        "      agent.update(current_state, new_state, reward, verbose=False)\n",
        "\n",
        "      if env.terminate:\n",
        "\n",
        "          V[e,:] = agent.v\n",
        "          D[e,:] = agent.d\n",
        "\n",
        "          print('End of episode')\n",
        "          env.reset()\n",
        "\n",
        "          break\n",
        "\n",
        "  return env, V, D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OE224gi5nO-",
        "outputId": "8d56f046-6787-42b0-8285-b6d9e657484e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ran the track 0 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 10.0\n",
            "End of episode\n",
            "Ran the track 1 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.8\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 8.0\n",
            "End of episode\n",
            "Ran the track 2 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.32400000000000007\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.8800000000000003\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 6.4\n",
            "End of episode\n",
            "Ran the track 3 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.05832000000000001\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.7776000000000002\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.4560000000000013\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 5.119999999999999\n",
            "End of episode\n",
            "Ran the track 4 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.010497600000000003\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.18662400000000007\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.2441600000000004\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.686400000000001\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 4.095999999999999\n",
            "End of episode\n",
            "Ran the track 5 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0018895680000000005\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.04199040000000001\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.37324800000000014\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.6588800000000004\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.6864\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.2767999999999997\n",
            "End of episode\n",
            "Ran the track 6 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0003401222400000001\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.009069926400000003\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.10077696000000003\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.5971968000000002\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.9906560000000004\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.538944\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.6214399999999998\n",
            "End of episode\n",
            "Ran the track 7 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 6.122200320000003e-05\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0019046845440000004\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.02539579392000001\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.18811699200000007\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.8360755200000003\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.22953472\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.3030144\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.0971519999999995\n",
            "End of episode\n",
            "Ran the track 8 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 1.1019960576000006e-05\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0003918208204800001\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.006094990540800003\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.05417769369600002\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.30098718720000006\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.0701766656000002\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.378170368\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.0198988799999995\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.6777216\n",
            "End of episode\n",
            "Ran the track 9 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 7.934371614720002e-05\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0014105549537280007\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.014627977297920008\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.09751984865280003\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.43342154956800016\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.28421199872\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.4461180928000004\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.717908992\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.3421772799999996\n",
            "End of episode\n",
            "Ran the track 10 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.00031737486458880017\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0037614798766080026\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.02925595459584001\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.1560317578444801\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.5778953994240001\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.46767085568\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.446118092800001\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.415919104000001\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.073741823999999\n",
            "End of episode\n",
            "Ran the track 11 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0009309662694604805\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.008275255728537604\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.05149048008867843\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.22884657817190412\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.7264970735616002\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.614437941248\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.39175991296\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.12600881152\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.8589934591999988\n",
            "End of episode\n",
            "Ran the track 12 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.002234319046705154\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0158884909987922\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.08238476814188549\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.3138467357786113\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.8717964882739202\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.7220671373312004\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.2960895164416\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.8554258718719998\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.6871947673599994\n",
            "End of episode\n",
            "Ran the track 13 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.004647383617146719\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.027540051064573152\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.12240022695365843\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.4080007565121947\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.007409275338752\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.7909498228244487\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.1708482700902394\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.6080357556224003\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.5497558138879999\n",
            "End of episode\n",
            "Ran the track 14 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.008675116085340544\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.044064081703317035\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.17136031773512178\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.5077342747707312\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.1282983883794027\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.823512546875802\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.0261250520842244\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.3853846509977599\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.4398046511103999\n",
            "End of episode\n",
            "Ran the track 15 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.014871627574869501\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.06609612255497554\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.228480423646829\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.6092811297248775\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.2308709691411666\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.8235125468758016\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.8702692788469761\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.1874725579980785\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.3518437208883203\n",
            "End of episode\n",
            "Ran the track 16 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.023794604119791198\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.09400337430040964\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.2924549422679412\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.7089816782253119\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.3129290337505772\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.7954585076930965\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.7099604835172357\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.0133099161583603\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.2814749767106566\n",
            "End of episode\n",
            "Ran the track 17 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.035956290669906694\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.12784458904855717\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.3615806558949091\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.8035125686553535\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.3735257583852194\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.74415969318758\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.5503641717222933\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.861313428734606\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.2251799813685249\n",
            "End of episode\n",
            "Ran the track 18 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.05177705856466564\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.16736018929992935\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.43389678707389084\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.8900446914336222\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.41276935148194\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.6743933054600761\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.3953277545500633\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.7295831396340215\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.18014398509481921\n",
            "End of episode\n",
            "Ran the track 19 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0715464809257198\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.21198957311324385\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.5073254741171647\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.9663342364136469\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.4316062761683654\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.5906736401870725\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.2475871687741744\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.6160924290242864\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.14411518807585466\n",
            "End of episode\n",
            "Ran the track 20 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.09539530790095974\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.26091024383168476\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.5798005418481883\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.0307565188412229\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.4316062761683659\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.49710460252901\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.108966372243711\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.5188146770730828\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.11529215046068408\n",
            "End of episode\n",
            "Ran the track 21 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.12328009021047101\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.31309229259802174\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.6493766068699707\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.0822943447832845\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.4147638493899137\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.3972976290270758\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.9805597396681236\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.43580432874138886\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.09223372036854727\n",
            "End of episode\n",
            "Ran the track 22 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.15498068483602073\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.3673616233150121\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.7143142675569677\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.1204929687168121\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.383324652736805\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.2943388563619225\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.8628925709079489\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.3652455326594506\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0737869762948371\n",
            "End of episode\n",
            "Ran the track 23 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.19010964006551875\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.4224658668122639\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.7731401484146003\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.1453928124660748\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.33964071633459\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.1907917478529688\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.7560582526050599\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.3054780818606311\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.05902958103586897\n",
            "End of episode\n",
            "Ran the track 24 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.22813156807862245\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.4771379201644392\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.8246828249755735\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.157449578913086\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.2860550876812065\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.0887238837512863\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.6598326568189616\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.255007790074961\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.04722366482869589\n",
            "End of episode\n",
            "Ran the track 25 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.268390080092497\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.5301532446271545\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.8680871841848146\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.1574495789130856\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.2248143692201974\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.9897489852284416\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.5737675276686627\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.21250649172913505\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.037778931862956\n",
            "End of episode\n",
            "Ran the track 26 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.31013964810688543\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.5803782888549904\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9028106715522071\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.146426249590104\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.1580063127172773\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.8950773431631118\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.4972651906461749\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.1768054011186404\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.03022314549036409\n",
            "End of episode\n",
            "Ran the track 27 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.3525798104794065\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.6268085519633895\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9286052621679843\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.1255821359611935\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.0875189719431813\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.8055696088468016\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.42963712471829485\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.14688448708317736\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.024178516392291627\n",
            "End of episode\n",
            "Ran the track 28 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.3948893877369353\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.6685957887609488\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9454889942074025\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.0962191237187278\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 1.0150177071469697\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.721790369526734\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.37014890744960827\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.1218597226171525\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.019342813113834012\n",
            "End of episode\n",
            "Ran the track 29 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.43625875216651894\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7050646499660917\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9537106376352926\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.0596784862614363\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.9419364322323887\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.644059098962317\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.31805387603077406\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.10096948445421283\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.01547425049106721\n",
            "End of episode\n",
            "Ran the track 30 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.4759186387271117\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7357196347472259\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9537106376352931\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 1.0172913468109792\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.8694797835991279\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.5724969768553931\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.272617608026378\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.08356095265176045\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.012379400392854123\n",
            "End of episode\n",
            "Ran the track 31 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5131644452361899\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7602436225721332\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9460809525342109\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.9703394384966266\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.798633282713272\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.5070687509290632\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.23313505789841926\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.06907705419212107\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.009903520314283654\n",
            "End of episode\n",
            "Ran the track 32 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5473754082519359\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7784894695138647\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9315258609567612\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.92002554168569\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.7301790013378504\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.44761931116496534\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.19894191607331635\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.05704427701027015\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.007922816251426212\n",
            "End of episode\n",
            "Ran the track 33 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5780284311140442\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.790466230583309\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.9108252862688331\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.8674526535893645\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.6647146770799743\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.39390499382516886\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.16942150272050327\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.04706152853347234\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.006338253001141325\n",
            "End of episode\n",
            "Ran the track 34 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6047066663962309\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7963215359950369\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.8848017066611522\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.8136107647458877\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.6026746405525092\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.3456198655498257\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.1440082773124267\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.03879010836698171\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.00507060240091306\n",
            "End of episode\n",
            "Ran the track 35 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6271032095960913\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7963215359950369\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.8542913029831816\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.7593700470961613\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.5443512882409758\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.30241738235609805\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.12218884135599772\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.03194479512574944\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.004056481920731159\n",
            "End of episode\n",
            "Ran the track 36 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6450204441559797\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7908296633330023\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.820119650863854\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.7054792695603052\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.4899161594168788\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.2639278973289576\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.10350113620743517\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.02628600284633187\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.003245185536584927\n",
            "End of episode\n",
            "Ran the track 37 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6583656947247241\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7802852678218954\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.7830819892119383\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.6525683243432825\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.43943994905271566\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.22977252238050383\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.08753238947828734\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.021612935673649858\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0025961484292675863\n",
            "End of episode\n",
            "Ran the track 38 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6671439039877205\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7651829723156651\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.7439278897513417\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.6011538503041143\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.39291101327066347\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.1995738480104956\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.07391624000388575\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.017757655256188443\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0020769187434144243\n",
            "End of episode\n",
            "Ran the track 39 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6714480582069962\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.7460533980077733\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.7033500048558134\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.5516470626320107\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.3502521032584198\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.17296400160909542\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.06232936994922511\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.014579969578763396\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0016615349947315394\n",
            "End of episode\n",
            "Ran the track 40 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6714480582069962\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.723445719280265\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.6619764751584136\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.5043630286921248\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.3113352028963732\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.149590487878136\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.052487890483558175\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.01196305196206282\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.001329227995785942\n",
            "End of episode\n",
            "Ran the track 41 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.667378676036045\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.697912340952727\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.6203665252913124\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.4595307594750473\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.27599445013516277\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.1291202105895488\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.04414366174001749\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.009809702608890802\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0010633823966283984\n",
            "End of episode\n",
            "Ran the track 42 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6595271622003267\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.6699958473146177\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.5790087569385589\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.41730360860436644\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.24403719801424995\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.1112420275848427\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.037080675861613344\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.008039170918506144\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.000850705917303074\n",
            "End of episode\n",
            "Ran the track 43 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6482209822768925\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.6402182541006347\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.538321655099633\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.3777695825260592\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.2152533233766718\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.09566814372296406\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.031111591454623166\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.006584463799919504\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0006805647338428145\n",
            "End of episode\n",
            "Ran the track 44 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6338160715596284\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.6090725011984417\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.49865584893439596\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.3409612642286488\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.18942292457147047\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.08213460144020424\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.026074476647682587\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.005390072692026848\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0005444517870749621\n",
            "End of episode\n",
            "Ran the track 45 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.6166859074634226\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.5770160537669442\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.4602977067086744\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.30686513780578295\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.16632256791641264\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.07040108694874725\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.021829794402711045\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.004410059475294048\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0004355614296596144\n",
            "End of episode\n",
            "Ran the track 46 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5972116156487877\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.5444664302211168\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.4234738901719801\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.2754301724695809\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.14573024998390505\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.06025023255148643\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.018257646227720414\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.003606448637574644\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.00034844914372733626\n",
            "End of episode\n",
            "Ran the track 47 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5757732499588313\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.5117984444078498\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.388356543182109\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.24657558297276694\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.12742924184639204\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.05148656236217963\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.015255277736939021\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0029478797559310266\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.0002787593149822243\n",
            "End of episode\n",
            "Ran the track 48 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.552742319960478\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.47934293329905975\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.3550688394807855\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.22019772991056463\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.11121097470230534\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.043935199882392695\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.012734840545618908\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.002408480481440378\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.00022300745198577943\n",
            "End of episode\n",
            "Ran the track 49 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5284755839622135\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.44738673774578874\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.3236906629685299\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.19617615937486654\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.09687711574067492\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.03744043120412588\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.010621398923154501\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.001966925726510027\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.000178405961587913\n",
            "End of episode\n",
            "Ran the track 50 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.5033100799640127\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.4161737095309661\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.2942642390622998\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.1743788083332154\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.084240970209283\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.031864196769467945\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.008851165769295122\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0016056536542929933\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.00014272476927068567\n",
            "End of episode\n",
            "Ran the track 51 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.47755933168678455\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.385906530655987\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.26679957674981836\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.15466642130424368\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0731283315859299\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.02708456725404762\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.007369950273208303\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0013102133819042905\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 0.00011417981541583799\n",
            "End of episode\n",
            "Ran the track 52 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.4515106408675047\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.3567491483397571\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.24127961723461855\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.13689623672886242\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.06337788737447259\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.022994244852415413\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.006131798627309948\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0010687230722989938\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 9.13438523326704e-05\n",
            "End of episode\n",
            "Ran the track 53 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.4254233593951606\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.32882964977403617\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.21766501639889047\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.1209250091104952\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.05484127397301286\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.019499119634849293\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.005097809054859681\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0008714203512578678\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 7.307508186649159e-05\n",
            "End of episode\n",
            "Ran the track 54 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.39952802447545466\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.30224342277102956\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.19589851475900133\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.10661143660353822\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.04738286071268405\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.016516901337754852\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.004235102907113486\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0007102897957445009\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 5.846006549248273e-05\n",
            "End of episode\n",
            "Ran the track 55 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.3740262356791493\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.2770564708734433\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.1759088703958369\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.09381806421111438\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.04087933081094164\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.013975839593484807\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0035159344889255095\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0005787546483837502\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 4.676805239434145e-05\n",
            "End of episode\n",
            "Ran the track 56 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.34909115330053897\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.2533087733700059\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.1576143478746701\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.08241273091486079\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0352191157755799\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.011813539882795432\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.002916923427848772\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.00047142196813787507\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.7414441916183705e-05\n",
            "End of episode\n",
            "Ran the track 57 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.32486850184703275\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.23101760131344484\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.14092576986441152\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.07226962557149275\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.030301729799367294\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.009975878123248627\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.002418394696544368\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.00038387217405499996\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.9931553532591693e-05\n",
            "End of episode\n",
            "Ran the track 58 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.30147796971404617\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.21018071962634988\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.125749148494398\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.06327001182108116\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.026037041901678215\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00841601354397703\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0020038127485655366\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0003124854188794046\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.3945242826783897e-05\n",
            "End of episode\n",
            "Ran the track 59 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.2790149053039803\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.1907794224300705\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.11198792092331367\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.05530267699916713\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.022344515959258793\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.007093497129923243\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0016592975742515392\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.0002542984788114211\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.9156194261071846e-05\n",
            "End of episode\n",
            "Ran the track 60 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.2575522202805969\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.17278136371025354\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.09954481859850084\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.048264154472000165\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.019152442250793378\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00597347126730341\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0013732117855873582\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.00020688689801673377\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.532495540956802e-05\n",
            "End of episode\n",
            "Ran the track 61 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.23714242169232325\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.15614315831593384\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.08832340268376004\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.04205876318274271\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.016397178628749565\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0050259551352489495\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.001135809070111904\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.00016826801038760664\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.2259964327299144e-05\n",
            "End of episode\n",
            "Ran the track 62 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.21781970585072674\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.14081273913582315\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.07822929951990165\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.03659850269936893\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.014022414827344676\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.004225209740819302\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0009389354979578712\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.00013682120188818203\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 9.807971462549858e-06\n",
            "End of episode\n",
            "Ran the track 63 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.1996020577250306\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.12673146522224066\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.06917117010180807\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.031802836828416226\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.011978469615223197\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.003549176182287006\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0007757762147075908\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 0.00011122239637373355\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 7.846377169329344e-06\n",
            "End of episode\n",
            "Ran the track 64 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.18249330992002788\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.11383598279611729\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.06106144671056146\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.027598393993473636\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.010221627404990663\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0029789806644773265\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0006406410031143395\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 9.039026498847136e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 6.277101736174018e-06\n",
            "End of episode\n",
            "Ran the track 65 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.16648512483932265\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.10205984664479484\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.05381686828727528\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.023918608127676322\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.008713518443598467\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.002498499912142904\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0005287830501874424\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 7.344209030435422e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 5.021681388939214e-06\n",
            "End of episode\n",
            "Ran the track 66 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.15155887226752096\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.09133491360754586\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.04735884409280189\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.020703319821989474\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.007420544739064283\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.002093980878748347\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0004362460164042403\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 5.965757489256873e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 4.0173451107961e-06\n",
            "End of episode\n",
            "Ran the track 67 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.1376873822633753\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.08159252282274121\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.041613672842199634\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.01789835391062322\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0063133523494265376\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0017537089859516186\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0003597351766035928\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 4.8449182036947036e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.2138760879263373e-06\n",
            "End of episode\n",
            "Ran the track 68 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.12483655991879328\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.07276447936978858\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.03651264197767112\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.01545508655139649\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.005366349497012202\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.001467719520550581\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0002965089940474286\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.933784332588175e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.5711008699857985e-06\n",
            "End of episode\n",
            "Ran the track 69 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.1129668542215958\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.06478385905181216\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.03199202916138777\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.013330012150579051\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.004557269111308493\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0012275472353699968\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.00024428800703724107\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.193307281534885e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.0568806959886388e-06\n",
            "End of episode\n",
            "Ran the track 70 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.10203457800660232\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.057585652490500294\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.02799302551621441\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.011484318160499107\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.003866773791413536\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0010260096295624521\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0002011783587363425\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.591669677798336e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.6455045575014537e-06\n",
            "End of episode\n",
            "Ran the track 71 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.09199307985357219\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.05110726658531917\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.024461597681860958\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.009883473810853971\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0032781007664519635\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0008570198082225033\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0001656076924092531\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.1029548241457974e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.3164036456458916e-06\n",
            "End of episode\n",
            "Ran the track 72 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.08279377186821435\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.045288900850990466\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.02134830343144234\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.008496837186644512\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0027767441786421543\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0007154252312124854\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.0001362714726109715\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.7060591249062895e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.0531229168719847e-06\n",
            "End of episode\n",
            "Ran the track 73 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.07438701964774985\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.04007381529845233\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.018608073438749706\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.007297283701471535\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.002350171884531349\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00059686905003975\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 0.000112088084513573\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.3838035123114878e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 8.424983342081305e-07\n",
            "End of episode\n",
            "Ran the track 74 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.06672290247192159\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.03540850545773733\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.016199969817264126\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.006260857900393546\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0019875739366312928\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0004976710952444563\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 9.216131393330329e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.1222077798578312e-05\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 6.739986666559616e-07\n",
            "End of episode\n",
            "Ran the track 75 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.059751852959930574\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.031242798933297067\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.014086930275882814\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.005366449628907866\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.001679639946449818\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0004147259127034175\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 7.574902515194992e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 9.098981999855482e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 5.391989326142266e-07\n",
            "End of episode\n",
            "Ran the track 76 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.05342518617593761\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.027529886596296294\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.012235505153909365\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.004595494893486318\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0014183626214467893\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.0003454155546895876\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 6.223703688235105e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 7.376241406120698e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 4.313591457361099e-07\n",
            "End of episode\n",
            "Ran the track 77 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.047695528528083564\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.024226300204740703\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.010615593203954887\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.003931701186649761\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0011968648970013263\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00028753511039081303\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 5.1117352958485185e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 5.978637771519857e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.450873169441593e-07\n",
            "End of episode\n",
            "Ran the track 78 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.04251715685932034\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.021291846940504122\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.009200180776760547\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0033607966307807047\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0010092482374721712\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00023922921184382773\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 4.19700371665499e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 4.845025934230307e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.7606985320005606e-07\n",
            "End of episode\n",
            "Ran the track 79 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.037846257936746674\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.018689510092220196\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.00796508801494955\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0028703019873690394\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0008504598481104964\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00019893797616621356\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 3.44481344001224e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.9257133206405115e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.2085588291531622e-07\n",
            "End of episode\n",
            "Ran the track 80 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.03364111816599724\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.01638532391646752\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.00688872476968605\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.002449324362554073\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0007161767141985464\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00016535104512360732\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.8265135918914552e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.180324716467453e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.766847059769816e-07\n",
            "End of episode\n",
            "Ran the track 81 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.029862252837761005\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.014348229591718109\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.00595185820100852\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0020883712985995118\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.000602704559480749\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00013736856056478786\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.3184567183420768e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.5760630197879664e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.4134776549212802e-07\n",
            "End of episode\n",
            "Ran the track 82 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.026472483596718277\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.012549918149555417\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.005137393394554657\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0017791838595870857\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0005068899884861366\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 0.00011406807054470391\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.9011345090191867e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.08629301567953e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.1307821168315968e-07\n",
            "End of episode\n",
            "Ran the track 83 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.023436972144294188\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.010964665330665646\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.004430167810369312\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0015145872855972797\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00042604424348713366\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 9.467649855210425e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.55846088123468e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.68938849043343e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 9.046256899125638e-08\n",
            "End of episode\n",
            "Ran the track 84 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.020723217474954758\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.009569162470398851\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0038167599597027646\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0012883577923057388\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0003578771645287304\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 7.854642842808346e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.2771776978226512e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.367794055795457e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 7.237005483773373e-08\n",
            "End of episode\n",
            "Ran the track 85 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.01830102322463567\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.008342346769064868\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0032853123703775466\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0010951041234594783\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.0003004400887398617\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 6.513606259872518e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.0463624512624392e-05\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.1072618555374447e-06\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 5.789604351491562e-08\n",
            "End of episode\n",
            "Ran the track 86 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.01614244099814055\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.007265233641919444\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0028253686385246723\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0009301625147415393\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00025207656225934016\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 5.399230249114595e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 8.570206745162068e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 8.962307713744622e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 4.6316834811932495e-08\n",
            "End of episode\n",
            "Ran the track 87 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.014221694854057887\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.006320753268470369\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.002427724163473144\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0007895037930003568\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00021137986425578958\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 4.473647920733015e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 7.017486932880956e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 7.253216480762603e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.7053467849545996e-08\n",
            "End of episode\n",
            "Ran the track 88 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.012515091471570372\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.00549359296420171\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.002084290013518064\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.000669651409966221\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00017715645766180899\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 3.705233101403138e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 5.744547445729609e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 5.869269426028723e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.964277356909406e-08\n",
            "End of episode\n",
            "Ran the track 89 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.011000919910811646\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.004770046573795206\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0017879692646083356\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0005676092903525998\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00014839458571103137\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 3.0675883350816946e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 4.701284806785111e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 4.748772539642232e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.3714218144732513e-08\n",
            "End of episode\n",
            "Ran the track 90 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.009659344311932827\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.00413787172666602\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0015325450839505095\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00048079845771020757\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00012423732757138595\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 2.5386937946514365e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 3.846505750360052e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.841703630769189e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.8971373805243275e-08\n",
            "End of episode\n",
            "Ran the track 91 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.008472292360345968\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0035861554964435882\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0013125797895483515\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0004070014851311754\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 0.00010395951088693067\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 2.1001921393093426e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 3.1463552652155613e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 3.1075113682277333e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.5177098688923252e-08\n",
            "End of episode\n",
            "Ran the track 92 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.00742334187763749\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0031051887592727923\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0011233240989625415\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00034431390006517404\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 8.694795456065663e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.736788106221354e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.573019418861122e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.5133278569455797e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 1.2141679661681337e-08\n",
            "End of episode\n",
            "Ran the track 93 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.006497607478778811\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.002686349345231598\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0009606357811824395\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0002911017518725245\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 7.268458223919083e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.4357448344881618e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 2.103655436513918e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 2.0325173188950885e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 9.713343018802334e-09\n",
            "End of episode\n",
            "Ran the track 94 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.005681628865165322\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.002321993916797993\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.000820906940282029\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.0002459646263002213\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 6.073200649403532e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 1.1864616653589621e-05\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.7195096617683703e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.643497853365261e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 7.770674770313235e-09\n",
            "End of episode\n",
            "Ran the track 95 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.004963261997155577\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0020053583826893373\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0007009991849606934\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00020770346220899683\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 5.07212361924303e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 9.80120506266502e-06\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.4051906909173795e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.3287854905286167e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 6.216540171521956e-09\n",
            "End of episode\n",
            "Ran the track 96 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.004331574106608116\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0017304665594446433\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0005981859711656767\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00017529259228243887\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 4.2341205864993015e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 8.09389837552743e-06\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 1.1480706909594574e-06\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 1.0742181544287632e-07\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 4.973232492488933e-09\n",
            "End of episode\n",
            "Ran the track 97 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0037767432659867595\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0014920467223653588\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.0005101014435426876\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00014785549088180971\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 3.532986639953606e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 6.6817714241551585e-06\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 9.377924801157178e-07\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 8.68326353042903e-08\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.978586349262514e-09\n",
            "End of episode\n",
            "Ran the track 98 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0032899630228149235\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.001285455637730415\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.00043469514319305347\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00012464376865839455\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 2.9466611975337287e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 5.51421978656208e-06\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 7.658638594421063e-07\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 7.018225289812108e-08\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 3.182869079410011e-09\n",
            "End of episode\n",
            "Ran the track 99 times so far\n",
            "Current state: 1\n",
            "Moving right...\n",
            "New state: 2\n",
            "delta: 0.0028633524330432536\n",
            "Current state: 2\n",
            "Moving right...\n",
            "New state: 3\n",
            "delta: 0.0011066096359586552\n",
            "Current state: 3\n",
            "Moving right...\n",
            "New state: 4\n",
            "delta: 0.00037019199291332683\n",
            "Current state: 4\n",
            "Moving right...\n",
            "New state: 5\n",
            "delta: 0.00010501900508241846\n",
            "Current state: 5\n",
            "Moving right...\n",
            "New state: 6\n",
            "delta: 2.4565849141566787e-05\n",
            "Current state: 6\n",
            "Moving right...\n",
            "New state: 7\n",
            "delta: 4.549231324091352e-06\n",
            "Current state: 7\n",
            "Moving right...\n",
            "New state: 8\n",
            "delta: 6.253238922226956e-07\n",
            "Current state: 8\n",
            "Moving right...\n",
            "New state: 9\n",
            "delta: 5.671871861068212e-08\n",
            "Current state: 9\n",
            "Moving right...\n",
            "New state: 10\n",
            "delta: 2.546295618799377e-09\n",
            "End of episode\n"
          ]
        }
      ],
      "source": [
        "n_episodes = 100\n",
        "\n",
        "params = {\n",
        "    'n_states': 10,\n",
        "    'alpha': 0.2,\n",
        "    'gamma': 0.9\n",
        "}\n",
        "\n",
        "env, V, D = run_simulation(params, n_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGYVEnN856jW"
      },
      "source": [
        "To visualize our results, we can plot the value function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "oS1b5HDd6CdC",
        "outputId": "ef0a03b2-c93c-4260-d78e-ae5b55cd3ab2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Value\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_wide \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(V\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      3\u001b[0m df_wide\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df_wide\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Value\n",
        "df_wide = pd.DataFrame(V.T)\n",
        "df_wide.loc[len(df_wide.index)-1] = 10\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(9,4))\n",
        "sns.lineplot(data=df_wide, legend=False, palette='Blues', markers=True, dashes=False)\n",
        "ax.legend(labels=list(np.arange(params['n_states'])+1))\n",
        "ax.axvline(x=params['n_states']-1, color='blue',linewidth=4)\n",
        "ax.set_xticks(np.arange(params['n_states']))\n",
        "labels = [str(i) for i in np.arange(params['n_states'])+1]\n",
        "labels[-1] = 'R'\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_xlabel('State',fontsize=15);\n",
        "ax.set_ylabel('Value',fontsize=15);\n",
        "sns.set_style('white');\n",
        "sns.despine();\n",
        "plt.gca().get_legend().remove()\n",
        "\n",
        "# TD-error\n",
        "df_wide = pd.DataFrame(D.T)\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(9,4))\n",
        "sns.lineplot(data=df_wide, legend=False, palette='Greens', markers=True, dashes=False)\n",
        "ax.legend(labels=list(np.arange(params['n_states'])+1))\n",
        "ax.axvline(x=params['n_states']-1, color='green',linewidth=4)\n",
        "ax.set_xticks(np.arange(params['n_states']))\n",
        "labels = [str(i) for i in np.arange(params['n_states'])+1]\n",
        "labels[-1] = 'R'\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_xlabel('State',fontsize=15);\n",
        "ax.set_ylabel('Reward prediction error',fontsize=15);\n",
        "sns.set_style('white');\n",
        "sns.despine();\n",
        "plt.gca().get_legend().remove()\n",
        "\n",
        "env.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nir8CpLdCECl"
      },
      "source": [
        "One nice intuition for what TD-Learning does is “backing up errors”.\n",
        "Each line on the value plot  shows you what happens to the value of states preceding the reward when we apply TD-Learning over many episodes (darker lines mean later episodes).  \n",
        "\n",
        "In early episodes, only the value of states immediately before the reward becomes positive (because that state predicts the imminent reward).\n",
        "\n",
        "But as the agent experiences this track more and more times, the error gets propagated backwards to earlier states in the track — they each acquire a bit of predictive value.\n",
        "\n",
        "This is exactly how we think conditioning works: if you walk multiple times to your favorite restaurant and take the same route, in time, you will learn to predict that different parts of your route (like a park or a street corner) lead to reward.\n",
        "\n",
        "*Discussion question*: What happens to the reward prediction error as the agent experiences the track multiple times? Why?  \n",
        "\n",
        "*Exercise*: Suppose reward was omitted on a random episode during the task. What do you think would happen to the RPE when the agent reaches the last state during that episode? You can verify your intuition in simulation by modifying the code above. This is exactly the experiment that led to the **[reward prediction error hypothesis](https://www.science.org/doi/10.1126/science.275.5306.1593)** of dopamine function. For a current view of this topic, see this [review](https://www.nature.com/articles/s41593-024-01705-4) by Gershman et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-euxY6XTWI2"
      },
      "source": [
        "### Q-Learning\n",
        "\n",
        "The TD-Learning algorithm tells us how to update our predictions, but does not tell us how to act. It is possible to extend the logic of learning from temporal differences to estimate $q_\\pi(s, a)$ which is the state-action value function for a particular policy.\n",
        "\n",
        "In fact, if it turns out that if we make the additional assumption that the agent's policy is to simply choose the best action *at the current timestep*, we end up with an update algorithm that [provably](https://link.springer.com/article/10.1007/BF00992698) converges to the optimal policy with enough experience. This is known as **Q-Learning**, and proceeds as follows:\n",
        "\n",
        "Within one episode, Q-Learning works as follows:\n",
        "\n",
        "1. Initialize $t = 0$\n",
        "2. Start in $S_0$\n",
        "3. At time step $t$, pick the action $A_t$ with the largest Q-Value.\n",
        "4. After applying action $A_t$, we observe reward $R_{t+1}$ and encounter the next state $S_{t+1}$.\n",
        "5. Update the Q-value function according to:\n",
        "\n",
        "$$\n",
        "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha[R_{t+1} + \\gamma \\max\\limits_{a}Q(S_{t+1},a) - Q(S_t,A_t)]\n",
        "$$\n",
        "\n",
        "6. $t = t+1$ and repeat from Step 3.\n",
        "\n",
        "In the next section, we will show how we can take Q-Learning and turn it into a model of human behavior which we can test against behavioral data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdT4SWM6Timx"
      },
      "source": [
        "## From RL algorithms to modeling human behavior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkDL0MTT3-L"
      },
      "source": [
        "### Simulating behavior\n",
        "\n",
        "To see how we can apply these ideas to modeling human behavioral data, let's consider a simple environment in which on each trial $t$, a participant makes a choice $c_t$ (= Left or Right) between a left and a right slot machine, and receives a reward $r_t$ (= $\\$1$ or $\\$0$) stochastically with probability $0.8$ if it chooses Left, or with probability $0.2$ if it chooses Right. This environment is called a **2-armed bandit**.\n",
        "\n",
        "Let's code up this environment below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "V7pPwqqFat3N"
      },
      "outputs": [],
      "source": [
        "class Bandit(object):\n",
        "\n",
        "  \"\"\"Class for the multiarmed bandit environment.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  k : int\n",
        "      Number of arms (actions).\n",
        "  best_action: int\n",
        "      Best action.\n",
        "  p_best : float, range (0, 1)\n",
        "      Reward probability for the best action.\n",
        "  p_other: float, range (0, 1)\n",
        "      Reward probability for the other arms.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, k, best, p_best, p_other, labels=None):\n",
        "\n",
        "    self.k = k              # number of arms\n",
        "    self.best_action = best # best action\n",
        "    self.p_best = p_best    # probability of reward for best action\n",
        "    self.p_other = p_other  # probability of reward for other actions\n",
        "    self.t = 0              # initialize timestep\n",
        "    self.labels = labels\n",
        "\n",
        "  def visualize(self):\n",
        "\n",
        "    # this method lets us visualize the structure of the environment\n",
        "    # in the multiarmed bandit case, this consists of the reward distribution for each arm\n",
        "\n",
        "    p_reward = np.ones((self.k, ))*self.p_other\n",
        "    p_reward[self.best_action-1] = self.p_best\n",
        "\n",
        "    sns.barplot(p_reward)\n",
        "    if self.labels == None:\n",
        "      labels = np.arange(self.k)+1\n",
        "    else:\n",
        "      labels = self.labels\n",
        "    plt.xticks(np.arange(self.k), labels)\n",
        "    plt.xlabel('Action')\n",
        "    plt.ylabel('Reward probability')\n",
        "\n",
        "  def step(self, action):\n",
        "\n",
        "    # the step method takes as input an action and changes the environment\n",
        "    # in the bandit case, the environment responds with a reward\n",
        "\n",
        "     # draw reward\n",
        "    if action == self.best_action:\n",
        "      reward = np.random.choice([1,0], p=[self.p_best, self.p_other])\n",
        "    else:\n",
        "      reward = np.random.choice([1,0], p=[self.p_other, self.p_best])\n",
        "\n",
        "    # increment timestep\n",
        "    self.t = self.t + 1\n",
        "\n",
        "    # comment the next line in if you want to print the time step\n",
        "    # print('timestep: ' + str(self.t))\n",
        "\n",
        "    return reward\n",
        "\n",
        "  def reset(self):\n",
        "\n",
        "    # the reset method resets the environment to its start state\n",
        "    self.t = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Exercise*: Use the bandit class to instantiate a four-armed bandit in which the probability of reward for taking the best action is 0.8, and 0.2 otherwise. Visualize to verify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "weYqN17ddznP",
        "outputId": "e6fcb6ac-9bcf-4e5b-87dc-1b99498ccc9d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fourarmed = Bandit(4, 1, 0.8, 0.2, labels=['A', 'B', 'C', 'D'])\n",
        "fourarmed.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSGPkbyEgllt"
      },
      "source": [
        "Now let's code up the Q-Learning agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "ReNm_0i3hpnK"
      },
      "outputs": [],
      "source": [
        "class QLearning(object):\n",
        "  \"\"\"Class for the Q-learning algorithm.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  alpha : float, range (0, 1)\n",
        "      Learning rate.\n",
        "\n",
        "  gamma : float, range (0, inf)\n",
        "      Discount factor.\n",
        "\n",
        "  beta : float, range (0, 1)\n",
        "      Inverse temperature.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, env, alpha, beta, epsilon, q_init=False):\n",
        "\n",
        "    # initialize action space\n",
        "    self.action_space = env.action_space\n",
        "\n",
        "    self.a = alpha\n",
        "    self.b = beta\n",
        "    self.eps = epsilon\n",
        "\n",
        "     # initialize Q-values\n",
        "    if q_init: # check if initial q-values were provided\n",
        "      self.q = np.ones((env.n_states+1, env.k))*q_init\n",
        "    else:\n",
        "      self.q = np.zeros((env.n_states+1, env.k))\n",
        "\n",
        "  def softmax(self, q_values):\n",
        "    \"\"\"Compute softmax probabilities for a vector of Q-values.\"\"\"\n",
        "    # numerical stability trick: subtract max\n",
        "    q_stable = q_values - np.max(q_values)\n",
        "    exp_q = np.exp(q_stable / self.beta)\n",
        "    return exp_q / np.sum(exp_q)\n",
        "\n",
        "  def policy(self, state):\n",
        "    \"\"\"Select action according to Softmax probabilities.\"\"\"\n",
        "    probs = self.softmax(self.q[state-1])\n",
        "    action = np.random.choice(np.arange(1, len(probs)+1), p=probs)\n",
        "    return action\n",
        "\n",
        "  def update(self, current_state, action, reward, new_state, verbose=False):\n",
        "\n",
        "    # we are at the start door\n",
        "    if current_state == 1:\n",
        "\n",
        "        # model-free learning\n",
        "        self.q[current_state-1, action-1] = self.q[current_state-1, action-1] + self.a*(reward + self.g * max(self.q[new_state-1, :]) - self.q[current_state-1, action-1])\n",
        "\n",
        "    # we are at one of the second doors\n",
        "    elif (current_state == 2) | (current_state == 3):\n",
        "\n",
        "      # model-free learning\n",
        "      self.q[current_state-1, action-1] = self.q[current_state-1, action-1] + self.a*(reward + self.g * max(self.q[new_state-1, :]) - self.q[current_state-1, action-1])\n",
        "\n",
        "    if verbose == True:\n",
        "      print(self.q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The likelihood function\n",
        "\n",
        "In a typical experiment, our data consists of stimuli, participant choices, and outcomes. The likelihood function is the statistical model that allows us to relate the algorithm to the data we observe. In general, if the data generated by an RL algorithm matches the data we obtain from our participants, we say that the algorithm is a good description of the cognitive process. \n",
        "\n",
        "We need a mathematical way to specify how to link between variables of the algorithm and choice data. The most common *link function* is the softmax [[1]](https://www.princeton.edu/~ndaw/d10.pdf)[[2]](https://elifesciences.org/articles/49547). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now implement that in code using the QLearning class we defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def qlearning_choice_loglik(\n",
        "    agent,\n",
        "    states,          # array-like, int, 1..n_states\n",
        "    actions,         # array-like, int, 1..k  (1-based indexing)\n",
        "    rewards,         # array-like, numeric\n",
        "    next_states,     # array-like, int, 1..n_states\n",
        "    beta,            # float, inverse temperature for softmax\n",
        "    include_mask=None,   # optional bool array, True to include that trial in the likelihood\n",
        "    init_q=None,         # optional float to (re)initialize agent.q before rolling; if None, keep current\n",
        "    return_per_trial=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Softmax observation model likelihood.\n",
        "\n",
        "    Likelihood per trial t:\n",
        "        P(a_t | s_t, Q, beta) = exp(beta * Q[s_t, a_t]) / sum_a exp(beta * Q[s_t, a])\n",
        "\n",
        "    Then the agent learns from the observed (s_t, a_t, r_t, s'_t) via agent.update(...).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    agent : QLearning\n",
        "        Your QLearning instance (has .q with shape (n_states+1, k), 1-based states/actions).\n",
        "    states, actions, rewards, next_states : same length arrays\n",
        "        Observed data. Use -1 or np.nan in `actions` to skip a trial (no likelihood, no update).\n",
        "    beta : float\n",
        "        Softmax inverse temperature.\n",
        "    include_mask : None or array-like of bool\n",
        "        If provided, only trials with mask==True contribute to likelihood and updates\n",
        "        (useful if you only want, e.g., first-step choices: include_mask = (states == 1)).\n",
        "    init_q : None or float\n",
        "        If given, fills agent.q with this value before rolling forward.\n",
        "        If None, uses agent.q as-is.\n",
        "    return_per_trial : bool\n",
        "        If True, also return vector of per-trial log-probs (np.nan for skipped).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    total_loglik : float\n",
        "    (optional) per_trial_logp : np.ndarray\n",
        "    \"\"\"\n",
        "    states      = np.asarray(states)\n",
        "    actions     = np.asarray(actions)\n",
        "    rewards     = np.asarray(rewards)\n",
        "    next_states = np.asarray(next_states)\n",
        "    assert len(states) == len(actions) == len(rewards) == len(next_states), \"All inputs must be same length\"\n",
        "\n",
        "    # Optionally (re)initialize Q-table to a known baseline\n",
        "    if init_q is not None:\n",
        "        agent.q[:] = init_q\n",
        "\n",
        "    T = len(actions)\n",
        "    per_logp = np.full(T, np.nan, dtype=float)\n",
        "\n",
        "    # Determine action-space size (k) from the Q-table’s second dimension\n",
        "    # agent.q shape is (n_states+1, k)\n",
        "    k = agent.q.shape[1]\n",
        "\n",
        "    # Trials to include\n",
        "    if include_mask is None:\n",
        "        include_mask = np.ones(T, dtype=bool)\n",
        "    else:\n",
        "        include_mask = np.asarray(include_mask, dtype=bool)\n",
        "        assert include_mask.shape == (T,), \"include_mask must match number of trials\"\n",
        "\n",
        "    for t in range(T):\n",
        "        if not include_mask[t]:\n",
        "            continue\n",
        "\n",
        "        a = actions[t]\n",
        "        s = states[t]\n",
        "        ns = next_states[t]\n",
        "        r = rewards[t]\n",
        "\n",
        "        # Skip trial if action is missing/invalid\n",
        "        if (a is None) or (isinstance(a, float) and np.isnan(a)) or (int(a) < 1):\n",
        "            continue\n",
        "\n",
        "        # Pull Q-values for current state (remember your table is 1-based for states)\n",
        "        # agent.q shape: (n_states+1, k), so state s maps to row s-1\n",
        "        Qs = np.asarray(agent.q[s-1, :], dtype=float)   # length k\n",
        "\n",
        "        # Numerically stable log-softmax\n",
        "        z = beta * Qs\n",
        "        z -= np.max(z)\n",
        "        log_denom = np.log(np.exp(z).sum())\n",
        "        chosen_idx = int(a) - 1     # 1..k -> 0..k-1\n",
        "        per_logp[t] = z[chosen_idx] - log_denom\n",
        "\n",
        "        # Roll the agent forward using the observed transition\n",
        "        agent.update(s, a, r, ns)\n",
        "\n",
        "    total_loglik = np.nansum(per_logp)\n",
        "\n",
        "    return (total_loglik, per_logp) if return_per_trial else total_loglik\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxSTSlseURgh"
      },
      "source": [
        "## Task examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTuqF-dLUiJo"
      },
      "source": [
        "[Attention-aware RL](https://www.cell.com/neuron/fulltext/S0896-6273(16)31039-X?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS089662731631039X%3Fshowall%3Dtrue)\n",
        "\n",
        "[A model of mood as reward prediction errors](https://www.sciencedirect.com/science/article/pii/S1364661315001746)\n",
        "\n",
        "[Working-memory limited RL](https://pmc.ncbi.nlm.nih.gov/articles/PMC4188972/pdf/zns13747.pdf)\n",
        "\n",
        "[The trade-off between habits and planning in compulsivity](https://elifesciences.org/articles/11305\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
